# Microservices Testing Guide

**For**: All Service Agents  
**Generated by**: Services Coordinator Agent  
**Date**: 2025-09-09  
**Purpose**: Standardized testing approach across all microservices

---

## ðŸŽ¯ **Testing Strategy Overview**

### **Testing Pyramid**
```
     ðŸ”º E2E Tests (10%)
    ðŸ”ºðŸ”º Integration Tests (20%)  
   ðŸ”ºðŸ”ºðŸ”º Unit Tests (70%)
```

### **Test Categories**
1. **Unit Tests**: Individual functions, classes, and modules
2. **Integration Tests**: Service interactions and database operations
3. **API Tests**: FastAPI endpoint testing with authentication
4. **Performance Tests**: Load and stress testing
5. **Security Tests**: Authentication, authorization, and input validation
6. **End-to-End Tests**: Full user workflows across services

---

## ðŸ“ **Standard Test Structure**

### **Required Test Directory Structure**
```
your-service/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py                    # Pytest fixtures and configuration
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_models.py             # Database model tests
â”‚   â”‚   â”œâ”€â”€ test_services.py           # Business logic tests
â”‚   â”‚   â””â”€â”€ test_utils.py              # Utility function tests
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_api_endpoints.py      # API endpoint tests
â”‚   â”‚   â”œâ”€â”€ test_auth_integration.py   # Authentication tests
â”‚   â”‚   â”œâ”€â”€ test_database.py           # Database integration
â”‚   â”‚   â””â”€â”€ test_service_communication.py # Inter-service tests
â”‚   â”œâ”€â”€ e2e/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ test_user_workflows.py     # End-to-end scenarios
â”‚   â””â”€â”€ fixtures/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ sample_data.py             # Test data fixtures
â”‚       â””â”€â”€ mock_responses.py          # Mock API responses
â”œâ”€â”€ pytest.ini                        # Pytest configuration
â””â”€â”€ test_requirements.txt              # Testing dependencies
```

### **pytest.ini Configuration**
```ini
[tool:pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = 
    --verbose
    --tb=short
    --cov=.
    --cov-report=html:htmlcov
    --cov-report=term-missing
    --cov-fail-under=80
    --ignore=venv
    --ignore=.venv
markers =
    unit: Unit tests
    integration: Integration tests
    e2e: End-to-end tests
    auth: Authentication tests
    slow: Slow running tests
    requires_db: Tests requiring database
    requires_redis: Tests requiring Redis
    requires_external: Tests requiring external services
asyncio_mode = auto
```

### **test_requirements.txt**
```txt
# Testing Framework
pytest==8.3.3
pytest-asyncio==0.24.0
pytest-cov==5.0.0
pytest-mock==3.14.0
pytest-timeout==2.3.1
pytest-xdist==3.6.1  # Parallel test execution

# FastAPI Testing
httpx==0.27.2
asgi-lifespan==2.1.0  # Async context manager for testing

# Database Testing
pytest-postgresql==6.0.0
sqlalchemy-utils==0.41.2
aiosqlite==0.20.0  # For SQLite async testing

# Mock and Factory
factory-boy==3.3.1
faker==26.0.0
responses==0.25.3
freezegun==1.5.1  # Time mocking

# Performance Testing
pytest-benchmark==4.0.0
locust==2.20.0
memory-profiler==0.61.0

# Test Utilities
python-multipart==0.0.9  # For file upload tests
aiofiles==24.1.0  # For async file operations in tests
python-magic==0.4.27  # For file type validation tests
```

---

## ðŸ§ª **Standard Test Implementation**

### **1. conftest.py - Test Configuration**

```python
import pytest
import asyncio
import os
import tempfile
from typing import AsyncGenerator, Dict, Any
from unittest.mock import AsyncMock, patch, MagicMock
from pathlib import Path

from fastapi.testclient import TestClient
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker
from sqlalchemy.pool import NullPool

from main import app
from database import get_db_session, Base
from config import get_settings

# Test configuration
os.environ["TESTING"] = "true"
os.environ["LOG_LEVEL"] = "ERROR"

# Test database URL
TEST_DATABASE_URL = "sqlite+aiosqlite:///:memory:"

@pytest.fixture(scope="session")
def event_loop():
    """Create event loop for async tests"""
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    yield loop
    loop.close()

@pytest.fixture
def client():
    """Test client for FastAPI app"""
    return TestClient(app)

@pytest.fixture(scope="session")
async def test_engine():
    """Create test database engine"""
    engine = create_async_engine(TEST_DATABASE_URL, echo=False)
    
    # Create tables
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)
    
    yield engine
    
    # Cleanup
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.drop_all)
    await engine.dispose()

@pytest.fixture
async def db_session(test_engine):
    """Create test database session"""
    async_session = sessionmaker(
        test_engine, class_=AsyncSession, expire_on_commit=False
    )
    
    async with async_session() as session:
        yield session
        await session.rollback()

@pytest.fixture
def override_get_db(db_session):
    """Override database dependency"""
    async def _get_test_db():
        yield db_session
    
    app.dependency_overrides[get_db_session] = _get_test_db
    yield
    app.dependency_overrides.clear()

# Authentication Fixtures
@pytest.fixture
def valid_jwt_token():
    """Mock valid JWT token"""
    return "valid.jwt.token"

@pytest.fixture
def invalid_jwt_token():
    """Mock invalid JWT token"""
    return "invalid.jwt.token"

@pytest.fixture
def expired_jwt_token():
    """Mock expired JWT token"""
    return "expired.jwt.token"

@pytest.fixture
def mock_user_data():
    """Mock authenticated user data"""
    return {
        "user_id": "test-user-123",
        "email": "test@example.com",
        "organization_id": "org-123",
        "roles": ["user"],
        "permissions": ["read", "write"],
        "is_active": True,
        "expires_at": "2025-12-31T23:59:59Z"
    }

@pytest.fixture
def admin_user_data():
    """Mock admin user data"""
    return {
        "user_id": "admin-user-123", 
        "email": "admin@example.com",
        "organization_id": "org-123",
        "roles": ["admin", "user"],
        "permissions": ["read", "write", "delete", "admin"],
        "is_active": True,
        "expires_at": "2025-12-31T23:59:59Z"
    }

@pytest.fixture
def mock_identity_service_success(mock_user_data):
    """Mock successful Identity Service authentication"""
    with patch('httpx.AsyncClient.post') as mock_post:
        mock_response = AsyncMock()
        mock_response.status_code = 200
        mock_response.json.return_value = mock_user_data
        mock_post.return_value = mock_response
        yield mock_post

@pytest.fixture
def mock_identity_service_failure():
    """Mock failed Identity Service authentication"""
    with patch('httpx.AsyncClient.post') as mock_post:
        mock_response = AsyncMock()
        mock_response.status_code = 401
        mock_response.json.return_value = {"detail": "Invalid token"}
        mock_post.return_value = mock_response
        yield mock_post

@pytest.fixture
def mock_redis():
    """Mock Redis client"""
    with patch('redis.asyncio.Redis') as mock_redis_class:
        mock_redis_instance = AsyncMock()
        mock_redis_class.return_value = mock_redis_instance
        yield mock_redis_instance
```

### **2. Unit Tests - test_models.py**

```python
import pytest
import uuid
from datetime import datetime
from sqlalchemy.ext.asyncio import AsyncSession

from models import YourModel  # Replace with your actual model
from tests.conftest import db_session, override_get_db

@pytest.mark.unit
@pytest.mark.asyncio
class TestYourModel:
    """Unit tests for database models"""
    
    async def test_model_creation(self, db_session: AsyncSession):
        """Test model can be created"""
        model_data = {
            "name": "Test Model",
            "description": "Test Description",
            "user_id": str(uuid.uuid4())
        }
        
        model = YourModel(**model_data)
        db_session.add(model)
        await db_session.commit()
        await db_session.refresh(model)
        
        assert model.id is not None
        assert model.name == model_data["name"]
        assert model.created_at is not None
        assert isinstance(model.created_at, datetime)
    
    async def test_model_validation(self):
        """Test model validation"""
        # Test required field validation
        with pytest.raises(TypeError):
            YourModel()  # Missing required fields
        
        # Test field type validation
        with pytest.raises(ValueError):
            YourModel(name="", description="test")  # Empty name
    
    async def test_model_relationships(self, db_session: AsyncSession):
        """Test model relationships"""
        # Create parent model
        parent = YourModel(name="Parent", description="Parent model")
        db_session.add(parent)
        await db_session.commit()
        
        # Test relationship
        assert hasattr(parent, 'children')  # Replace with actual relationship
    
    async def test_model_methods(self, db_session: AsyncSession):
        """Test custom model methods"""
        model = YourModel(name="Test", description="Test model")
        
        # Test to_dict method (if implemented)
        if hasattr(model, 'to_dict'):
            model_dict = model.to_dict()
            assert isinstance(model_dict, dict)
            assert 'name' in model_dict
```

### **3. Service Tests - test_services.py**

```python
import pytest
from unittest.mock import AsyncMock, patch
from sqlalchemy.ext.asyncio import AsyncSession

from services.your_service import YourService  # Replace with actual service
from models import YourModel
from tests.conftest import db_session, mock_redis

@pytest.mark.unit
@pytest.mark.asyncio
class TestYourService:
    """Unit tests for business logic services"""
    
    @pytest.fixture
    def service(self, db_session: AsyncSession):
        """Create service instance"""
        return YourService(db_session)
    
    async def test_create_item(self, service: YourService):
        """Test item creation"""
        item_data = {
            "name": "Test Item",
            "description": "Test Description"
        }
        
        created_item = await service.create_item(item_data)
        
        assert created_item.name == item_data["name"]
        assert created_item.id is not None
    
    async def test_get_item_by_id(self, service: YourService, db_session: AsyncSession):
        """Test item retrieval by ID"""
        # Create test item
        test_item = YourModel(name="Test", description="Test item")
        db_session.add(test_item)
        await db_session.commit()
        await db_session.refresh(test_item)
        
        # Test retrieval
        found_item = await service.get_item_by_id(test_item.id)
        
        assert found_item is not None
        assert found_item.id == test_item.id
    
    async def test_get_nonexistent_item(self, service: YourService):
        """Test retrieval of non-existent item"""
        non_existent_id = str(uuid.uuid4())
        
        found_item = await service.get_item_by_id(non_existent_id)
        
        assert found_item is None
    
    @patch('external_api.call_external_service')
    async def test_service_with_external_dependency(self, mock_external, service: YourService):
        """Test service that depends on external API"""
        # Mock external service response
        mock_external.return_value = {"status": "success", "data": {"key": "value"}}
        
        result = await service.process_with_external_api("test-data")
        
        assert result["status"] == "success"
        mock_external.assert_called_once_with("test-data")
    
    async def test_error_handling(self, service: YourService):
        """Test service error handling"""
        with pytest.raises(ValueError, match="Invalid input"):
            await service.validate_input(None)
    
    async def test_caching_behavior(self, service: YourService, mock_redis):
        """Test Redis caching behavior"""
        cache_key = "test_key"
        cache_value = {"data": "test_value"}
        
        # Mock Redis get/set
        mock_redis.get.return_value = None
        mock_redis.setex.return_value = True
        
        result = await service.get_cached_data(cache_key)
        
        # Verify Redis was called
        mock_redis.get.assert_called_once_with(cache_key)
```

### **4. API Tests - test_api_endpoints.py**

```python
import pytest
from fastapi.testclient import TestClient
from unittest.mock import patch, AsyncMock

from tests.conftest import (
    client, mock_identity_service_success, mock_identity_service_failure,
    mock_user_data, admin_user_data, valid_jwt_token
)

@pytest.mark.integration
class TestAPIEndpoints:
    """Integration tests for API endpoints"""
    
    def test_health_endpoint(self, client: TestClient):
        """Test health endpoint (no auth required)"""
        response = client.get("/health")
        
        assert response.status_code == 200
        data = response.json()
        assert "service" in data
        assert "status" in data
    
    @patch('httpx.AsyncClient.post')
    def test_authenticated_endpoint_success(self, mock_post, client: TestClient, mock_user_data):
        """Test successful authentication on protected endpoint"""
        # Mock Identity Service success
        mock_response = AsyncMock()
        mock_response.status_code = 200
        mock_response.json.return_value = mock_user_data
        mock_post.return_value = mock_response
        
        headers = {"Authorization": "Bearer valid.jwt.token"}
        response = client.get("/api/v1/protected-endpoint", headers=headers)
        
        assert response.status_code == 200
        # Verify Identity Service was called
        mock_post.assert_called_once()
    
    @patch('httpx.AsyncClient.post')
    def test_authenticated_endpoint_failure(self, mock_post, client: TestClient):
        """Test failed authentication on protected endpoint"""
        # Mock Identity Service failure
        mock_response = AsyncMock()
        mock_response.status_code = 401
        mock_response.json.return_value = {"detail": "Invalid token"}
        mock_post.return_value = mock_response
        
        headers = {"Authorization": "Bearer invalid.jwt.token"}
        response = client.get("/api/v1/protected-endpoint", headers=headers)
        
        assert response.status_code == 401
        assert "Invalid token" in response.json()["detail"]
    
    def test_unauthenticated_access(self, client: TestClient):
        """Test access to protected endpoint without authentication"""
        response = client.get("/api/v1/protected-endpoint")
        
        assert response.status_code == 401
        assert "Not authenticated" in response.json()["detail"]
    
    @pytest.mark.parametrize("endpoint,method,data", [
        ("/api/v1/your-endpoint", "GET", None),
        ("/api/v1/your-endpoint", "POST", {"name": "test", "description": "test"}),
        ("/api/v1/your-endpoint/123", "PUT", {"name": "updated"}),
        ("/api/v1/your-endpoint/123", "DELETE", None),
    ])
    def test_endpoint_without_auth(self, client: TestClient, endpoint, method, data):
        """Test protected endpoints require authentication"""
        if method == "GET":
            response = client.get(endpoint)
        elif method == "POST":
            response = client.post(endpoint, json=data)
        elif method == "PUT":
            response = client.put(endpoint, json=data)
        elif method == "DELETE":
            response = client.delete(endpoint)
        
        assert response.status_code == 401
    
    @patch('httpx.AsyncClient.post')
    def test_role_based_access(self, mock_post, client: TestClient, admin_user_data):
        """Test role-based access control"""
        # Mock admin user
        mock_response = AsyncMock()
        mock_response.status_code = 200
        mock_response.json.return_value = admin_user_data
        mock_post.return_value = mock_response
        
        headers = {"Authorization": "Bearer admin.jwt.token"}
        response = client.delete("/api/v1/admin-only-endpoint", headers=headers)
        
        # Should succeed for admin user
        assert response.status_code in [200, 204]
    
    def test_input_validation(self, client: TestClient):
        """Test API input validation"""
        # Test missing required fields
        invalid_data = {}
        response = client.post("/api/v1/your-endpoint", json=invalid_data)
        
        assert response.status_code == 422  # Validation error
        
        # Test invalid data types
        invalid_data = {"name": 123}  # Should be string
        response = client.post("/api/v1/your-endpoint", json=invalid_data)
        
        assert response.status_code == 422
    
    def test_rate_limiting(self, client: TestClient):
        """Test rate limiting (if implemented)"""
        # Make multiple rapid requests
        responses = []
        for i in range(100):
            response = client.get("/health")
            responses.append(response.status_code)
        
        # Check if any requests were rate limited
        rate_limited = any(status == 429 for status in responses)
        # This test might pass if rate limiting is not strict
        # Adjust based on your rate limiting configuration
```

### **5. Authentication Tests - test_auth_integration.py**

```python
import pytest
from fastapi.testclient import TestClient
from unittest.mock import patch, AsyncMock
import time

@pytest.mark.auth
class TestAuthenticationFlow:
    """Test authentication integration"""
    
    @patch('httpx.AsyncClient.post')
    def test_jwt_validation_success(self, mock_post, client: TestClient, mock_user_data):
        """Test successful JWT token validation"""
        mock_response = AsyncMock()
        mock_response.status_code = 200
        mock_response.json.return_value = mock_user_data
        mock_post.return_value = mock_response
        
        headers = {"Authorization": "Bearer valid.jwt.token"}
        response = client.get("/api/v1/protected-endpoint", headers=headers)
        
        assert response.status_code == 200
        # Verify the Identity Service validation endpoint was called
        args, kwargs = mock_post.call_args
        assert "auth/validate" in str(kwargs.get('url', ''))
    
    @patch('httpx.AsyncClient.post')
    def test_jwt_validation_timeout(self, mock_post, client: TestClient):
        """Test JWT validation timeout handling"""
        # Mock timeout
        import httpx
        mock_post.side_effect = httpx.TimeoutException("Timeout")
        
        headers = {"Authorization": "Bearer valid.jwt.token"}
        response = client.get("/api/v1/protected-endpoint", headers=headers)
        
        assert response.status_code == 503  # Service unavailable
        assert "Service temporarily unavailable" in response.json()["detail"]
    
    @patch('httpx.AsyncClient.post')
    def test_identity_service_down(self, mock_post, client: TestClient):
        """Test behavior when Identity Service is down"""
        import httpx
        mock_post.side_effect = httpx.ConnectError("Connection refused")
        
        headers = {"Authorization": "Bearer valid.jwt.token"}
        response = client.get("/api/v1/protected-endpoint", headers=headers)
        
        assert response.status_code == 503
    
    def test_missing_authorization_header(self, client: TestClient):
        """Test request without Authorization header"""
        response = client.get("/api/v1/protected-endpoint")
        
        assert response.status_code == 401
        assert "Not authenticated" in response.json()["detail"]
    
    def test_malformed_authorization_header(self, client: TestClient):
        """Test malformed Authorization header"""
        test_cases = [
            {"Authorization": "invalid-header"},
            {"Authorization": "Bearer"},  # Missing token
            {"Authorization": "Basic token"},  # Wrong scheme
            {"Authorization": "Bearer "},  # Empty token
        ]
        
        for headers in test_cases:
            response = client.get("/api/v1/protected-endpoint", headers=headers)
            assert response.status_code == 401
    
    @patch('httpx.AsyncClient.post')
    def test_user_context_extraction(self, mock_post, client: TestClient, mock_user_data):
        """Test user context is properly extracted from JWT"""
        mock_response = AsyncMock()
        mock_response.status_code = 200
        mock_response.json.return_value = mock_user_data
        mock_post.return_value = mock_response
        
        headers = {"Authorization": "Bearer valid.jwt.token"}
        response = client.get("/api/v1/user-info", headers=headers)
        
        assert response.status_code == 200
        data = response.json()
        assert data["user_id"] == mock_user_data["user_id"]
        assert data["organization_id"] == mock_user_data["organization_id"]
```

---

## ðŸ”§ **Test Commands**

### **Basic Test Commands**
```bash
# Run all tests
pytest

# Run tests with coverage
pytest --cov=. --cov-report=html

# Run specific test file
pytest tests/unit/test_models.py

# Run specific test class
pytest tests/unit/test_models.py::TestYourModel

# Run specific test function
pytest tests/unit/test_models.py::TestYourModel::test_model_creation

# Run tests by marker
pytest -m unit
pytest -m integration
pytest -m auth
pytest -m slow

# Run tests with verbose output
pytest -v

# Run tests and stop on first failure
pytest -x

# Run tests in parallel (with pytest-xdist)
pytest -n auto
```

### **Coverage Commands**
```bash
# Generate HTML coverage report
pytest --cov=. --cov-report=html

# Generate terminal coverage report
pytest --cov=. --cov-report=term-missing

# Set minimum coverage threshold
pytest --cov=. --cov-fail-under=80

# Coverage for specific module
pytest --cov=services --cov-report=term-missing
```

### **Performance Testing**
```bash
# Run benchmark tests
pytest --benchmark-only

# Run load tests with Locust
locust -f tests/load/locustfile.py --host=http://localhost:8002
```

---

## ðŸ“Š **Testing Standards**

### **Coverage Requirements**
- **Minimum Overall Coverage**: 80%
- **Unit Tests Coverage**: >90%
- **Integration Tests Coverage**: >70%
- **Critical Path Coverage**: 100%

### **Test Quality Standards**
- âœ… All tests must be deterministic (no flaky tests)
- âœ… Tests must be independent (no test order dependencies)
- âœ… Use descriptive test names that explain the scenario
- âœ… Follow AAA pattern: Arrange, Act, Assert
- âœ… Mock external dependencies appropriately
- âœ… Clean up test data after each test

### **Test Data Management**
```python
# Use factories for test data
import factory
from faker import Faker

fake = Faker()

class UserFactory(factory.Factory):
    class Meta:
        model = User
    
    id = factory.LazyFunction(lambda: str(uuid.uuid4()))
    email = factory.LazyFunction(fake.email)
    name = factory.LazyFunction(fake.name)
    organization_id = factory.LazyFunction(lambda: str(uuid.uuid4()))

# Usage in tests
def test_user_creation():
    user = UserFactory()
    assert user.email is not None
```

### **Mock Guidelines**
```python
# Good: Mock external dependencies
@patch('httpx.AsyncClient.post')
async def test_external_api_call(mock_post):
    mock_post.return_value.json.return_value = {"status": "success"}
    # Test your code

# Bad: Don't mock what you're testing
@patch('your_service.your_function')  # Don't do this
def test_your_function(mock_function):
    # This doesn't test your function
    pass

# Good: Mock at the boundary
@patch('your_service.external_dependency')
def test_your_function_with_external_dep(mock_external):
    # Test your function, mock external dependency
    pass
```

---

## ðŸš¨ **Common Testing Pitfalls**

### **âŒ What to Avoid**
1. **Flaky Tests**: Tests that pass/fail randomly
2. **Slow Tests**: Tests taking >1 second for unit tests
3. **Test Dependencies**: Tests that depend on other tests
4. **Over-mocking**: Mocking everything including what you're testing
5. **Under-mocking**: Not mocking external dependencies
6. **Hardcoded Values**: Using hardcoded IDs, dates, etc.
7. **No Assertions**: Tests that don't assert anything
8. **Testing Implementation**: Testing how, not what

### **âœ… Best Practices**
1. **Clear Test Names**: `test_user_creation_with_valid_email_succeeds`
2. **Single Responsibility**: One test, one scenario
3. **Independent Tests**: Each test can run in isolation
4. **Fast Unit Tests**: Unit tests should complete in milliseconds
5. **Realistic Test Data**: Use factories and realistic data
6. **Test Edge Cases**: Null values, empty strings, boundary conditions
7. **Clean Test Data**: Use fixtures and proper cleanup
8. **Document Complex Tests**: Add comments for complex test scenarios

---

## ðŸ“ˆ **Test Metrics and Monitoring**

### **Key Metrics to Track**
- Test coverage percentage
- Test execution time
- Test failure rate
- Flaky test detection
- Number of tests per category

### **CI/CD Integration**
```yaml
# Example GitHub Actions workflow
name: Test Suite
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r test_requirements.txt
      - name: Run tests
        run: |
          pytest --cov=. --cov-report=xml --cov-fail-under=80
      - name: Upload coverage
        uses: codecov/codecov-action@v3
```

---

## ðŸŽ¯ **Service-Specific Test Examples**

### **Identity Service Tests**
```python
import pytest
from unittest.mock import patch, AsyncMock
from fastapi.testclient import TestClient

@pytest.mark.asyncio
class TestIdentityService:
    """Identity Service specific tests"""
    
    async def test_mfa_setup_flow(self, client: TestClient, mock_user_data):
        """Test complete MFA setup workflow"""
        with patch('httpx.AsyncClient.post') as mock_post:
            # Mock successful auth
            mock_response = AsyncMock()
            mock_response.status_code = 200
            mock_response.json.return_value = mock_user_data
            mock_post.return_value = mock_response
            
            # Test TOTP setup
            headers = {"Authorization": "Bearer valid.token"}
            response = client.post("/api/v1/mfa/setup", 
                                  json={"method": "totp"}, 
                                  headers=headers)
            assert response.status_code == 200
            assert "qr_code" in response.json()
            assert "secret" in response.json()
    
    async def test_jwt_token_generation(self, client: TestClient):
        """Test JWT token generation with claims"""
        response = client.post("/api/v1/auth/login",
                              json={"email": "test@example.com", 
                                   "password": "SecurePass123!"})
        assert response.status_code == 200
        token_data = response.json()
        assert "access_token" in token_data
        assert "refresh_token" in token_data
        assert "expires_in" in token_data
    
    async def test_organization_management(self, client: TestClient, admin_user_data):
        """Test organization CRUD operations"""
        with patch('httpx.AsyncClient.post') as mock_post:
            mock_response = AsyncMock()
            mock_response.status_code = 200
            mock_response.json.return_value = admin_user_data
            mock_post.return_value = mock_response
            
            headers = {"Authorization": "Bearer admin.token"}
            
            # Create organization
            org_data = {
                "name": "Test Organization",
                "domain": "test.com",
                "settings": {"theme": "dark"}
            }
            response = client.post("/api/v1/organizations", 
                                  json=org_data, 
                                  headers=headers)
            assert response.status_code == 201
            org_id = response.json()["id"]
            
            # Get organization details
            response = client.get(f"/api/v1/organizations/{org_id}", 
                                 headers=headers)
            assert response.status_code == 200
            assert response.json()["name"] == "Test Organization"
```

### **Communication Service Tests**
```python
import pytest
from unittest.mock import patch, AsyncMock, MagicMock
from fastapi.testclient import TestClient

@pytest.mark.asyncio
class TestCommunicationService:
    """Communication Service specific tests"""
    
    @patch('tasks.notification_tasks.send_notification')
    async def test_send_email_notification(self, mock_task, client: TestClient, mock_user_data):
        """Test email notification sending"""
        with patch('httpx.AsyncClient.post') as mock_post:
            # Mock auth
            mock_response = AsyncMock()
            mock_response.status_code = 200
            mock_response.json.return_value = mock_user_data
            mock_post.return_value = mock_response
            
            # Mock Celery task
            mock_task.apply_async.return_value = MagicMock(id="task-123")
            
            headers = {"Authorization": "Bearer valid.token"}
            notification_data = {
                "type": "email",
                "to": "user@example.com",
                "subject": "Test Subject",
                "message": "Test message content",
                "template_id": None
            }
            
            response = client.post("/api/v1/notifications",
                                  json=notification_data,
                                  headers=headers)
            
            assert response.status_code == 200
            assert response.json()["task_id"] == "task-123"
            assert response.json()["status"] == "queued"
            mock_task.apply_async.assert_called_once()
    
    @patch('providers.in_app.InAppProvider')
    async def test_unread_notifications(self, mock_provider, client: TestClient, mock_user_data):
        """Test retrieving unread notifications"""
        with patch('httpx.AsyncClient.post') as mock_post:
            mock_response = AsyncMock()
            mock_response.status_code = 200
            mock_response.json.return_value = mock_user_data
            mock_post.return_value = mock_response
            
            # Mock in-app provider
            mock_provider_instance = AsyncMock()
            mock_provider_instance.get_unread_notifications.return_value = [
                {"id": "notif-1", "content": "Test notification", "is_read": False}
            ]
            mock_provider_instance.get_unread_count.return_value = 1
            mock_provider.return_value = mock_provider_instance
            
            headers = {"Authorization": "Bearer valid.token"}
            response = client.get("/api/v1/notifications/unread", headers=headers)
            
            assert response.status_code == 200
            assert response.json()["unread_count"] == 1
            assert len(response.json()["notifications"]) == 1
```

### **Content Service Tests**
```python
import pytest
import io
import tempfile
from pathlib import Path
from unittest.mock import patch, AsyncMock, MagicMock
from fastapi.testclient import TestClient

@pytest.mark.asyncio  
class TestContentService:
    """Content Service specific tests"""
    
    @pytest.fixture
    def sample_pdf_file(self):
        """Create a sample PDF file for testing"""
        # Create minimal PDF content
        pdf_content = b"%PDF-1.4\n1 0 obj\n<< /Type /Catalog >>\nendobj\nxref\n0 2\ntrailer\n<< /Root 1 0 R >>\n%%EOF"
        return io.BytesIO(pdf_content)
    
    async def test_file_upload_workflow(self, client: TestClient, mock_user_data, sample_pdf_file):
        """Test complete file upload workflow"""
        with patch('httpx.AsyncClient.post') as mock_post:
            mock_response = AsyncMock()
            mock_response.status_code = 200
            mock_response.json.return_value = mock_user_data
            mock_post.return_value = mock_response
            
            with tempfile.TemporaryDirectory() as tmpdir:
                # Mock storage directory
                with patch('main.STORAGE_DIRECTORY', Path(tmpdir)):
                    headers = {"Authorization": "Bearer valid.token"}
                    
                    files = {
                        "file": ("test.pdf", sample_pdf_file, "application/pdf")
                    }
                    data = {
                        "description": "Test document",
                        "tags": "test,upload",
                        "category": "reports"
                    }
                    
                    response = client.post("/api/v1/documents",
                                          files=files,
                                          data=data,
                                          headers=headers)
                    
                    assert response.status_code == 200
                    doc_data = response.json()
                    assert doc_data["filename"] == "test.pdf"
                    assert doc_data["content_type"] == "application/pdf"
                    assert doc_data["tags"] == ["test", "upload"]
    
    async def test_document_download(self, client: TestClient, mock_user_data, db_session):
        """Test document download with security checks"""
        with patch('httpx.AsyncClient.post') as mock_post:
            mock_response = AsyncMock()
            mock_response.status_code = 200
            mock_response.json.return_value = mock_user_data
            mock_post.return_value = mock_response
            
            # Create test document in DB
            from models import Document
            import uuid
            
            doc_id = uuid.uuid4()
            test_file = Path("/tmp/test.pdf")
            test_file.write_bytes(b"test content")
            
            document = Document(
                id=doc_id,
                filename="test.pdf",
                file_path=str(test_file),
                organization_id=mock_user_data["organization_id"],
                uploaded_by=mock_user_data["user_id"]
            )
            db_session.add(document)
            await db_session.commit()
            
            headers = {"Authorization": "Bearer valid.token"}
            response = client.get(f"/api/v1/documents/{doc_id}/download",
                                 headers=headers)
            
            assert response.status_code == 200
            assert response.headers["content-type"] == "application/pdf"
            
    async def test_document_search(self, client: TestClient, mock_user_data):
        """Test document search functionality"""
        with patch('httpx.AsyncClient.post') as mock_post:
            mock_response = AsyncMock()
            mock_response.status_code = 200
            mock_response.json.return_value = mock_user_data
            mock_post.return_value = mock_response
            
            headers = {"Authorization": "Bearer valid.token"}
            response = client.get("/api/v1/search?q=test+document",
                                 headers=headers)
            
            # Currently returns placeholder
            assert response.status_code == 200
```

### **Workflow Intelligence Service Tests**
```python
import pytest
from unittest.mock import patch, AsyncMock
from fastapi.testclient import TestClient

@pytest.mark.asyncio
class TestWorkflowService:
    """Workflow Intelligence Service specific tests"""
    
    async def test_workflow_state_machine(self, client: TestClient, mock_user_data):
        """Test workflow state transitions"""
        with patch('httpx.AsyncClient.post') as mock_post:
            mock_response = AsyncMock()
            mock_response.status_code = 200
            mock_response.json.return_value = mock_user_data
            mock_post.return_value = mock_response
            
            headers = {"Authorization": "Bearer valid.token"}
            
            # Create workflow
            workflow_data = {
                "name": "Test Workflow",
                "type": "sequential",
                "steps": [
                    {"name": "step1", "action": "validate"},
                    {"name": "step2", "action": "process"},
                    {"name": "step3", "action": "complete"}
                ]
            }
            
            response = client.post("/api/v1/workflows",
                                  json=workflow_data,
                                  headers=headers)
            assert response.status_code == 201
            workflow_id = response.json()["id"]
            
            # Test state transitions
            transitions = ["pending", "in_progress", "completed"]
            for state in transitions:
                response = client.post(f"/api/v1/workflows/{workflow_id}/transition",
                                      json={"state": state},
                                      headers=headers)
                assert response.status_code == 200
                assert response.json()["current_state"] == state
    
    @patch('openai.ChatCompletion.create')
    async def test_ai_analysis(self, mock_openai, client: TestClient, mock_user_data):
        """Test AI integration for workflow analysis"""
        with patch('httpx.AsyncClient.post') as mock_post:
            mock_response = AsyncMock()
            mock_response.status_code = 200
            mock_response.json.return_value = mock_user_data
            mock_post.return_value = mock_response
            
            # Mock OpenAI response
            mock_openai.return_value = {
                "choices": [{
                    "message": {
                        "content": "Workflow optimization suggestions..."
                    }
                }]
            }
            
            headers = {"Authorization": "Bearer valid.token"}
            analysis_request = {
                "workflow_id": "workflow-123",
                "analysis_type": "optimization",
                "context": {"current_efficiency": 0.75}
            }
            
            response = client.post("/api/v1/ai/analyze",
                                  json=analysis_request,
                                  headers=headers)
            
            assert response.status_code == 200
            assert "suggestions" in response.json()
            mock_openai.assert_called_once()
```

---

## ðŸ“‹ **Testing Checklist**

### **Before Writing Tests**
- [ ] Understand the requirement/feature being tested
- [ ] Identify happy path and edge cases
- [ ] Determine external dependencies to mock
- [ ] Plan test data requirements
- [ ] Choose appropriate test category (unit/integration/e2e)

### **While Writing Tests**
- [ ] Use descriptive test names
- [ ] Follow AAA pattern (Arrange, Act, Assert)
- [ ] Mock external dependencies appropriately
- [ ] Use realistic test data
- [ ] Test both success and failure scenarios
- [ ] Include edge cases and boundary conditions

### **After Writing Tests**
- [ ] Verify tests pass consistently
- [ ] Check test coverage meets standards
- [ ] Review test performance (execution time)
- [ ] Ensure tests are independent
- [ ] Add documentation for complex tests
- [ ] Run tests in CI/CD pipeline

---

## ðŸ³ **Docker & Integration Testing**

### **Docker Container Testing**
```python
import pytest
import docker
import time
from docker.errors import NotFound

@pytest.fixture(scope="session")
def docker_client():
    """Create Docker client for container testing"""
    return docker.from_env()

@pytest.fixture(scope="session") 
def service_container(docker_client):
    """Start service container for testing"""
    container = docker_client.containers.run(
        "your-service:latest",
        environment={
            "DATABASE_URL": "postgresql://test:test@db:5432/test",
            "REDIS_URL": "redis://redis:6379/0",
            "DEBUG": "false"
        },
        detach=True,
        ports={'8001/tcp': 8001},
        network="test-network"
    )
    
    # Wait for container to be healthy
    for _ in range(30):
        container.reload()
        if container.attrs['State']['Health']['Status'] == 'healthy':
            break
        time.sleep(1)
    
    yield container
    
    # Cleanup
    container.stop()
    container.remove()

def test_container_health(service_container):
    """Test container health check"""
    service_container.reload()
    assert service_container.attrs['State']['Health']['Status'] == 'healthy'

def test_container_endpoints(service_container):
    """Test container API endpoints"""
    import requests
    
    # Test health endpoint
    response = requests.get("http://localhost:8001/health")
    assert response.status_code == 200
    assert response.json()["status"] == "healthy"
```

### **Database Migration Testing**
```python
import pytest
from alembic import command
from alembic.config import Config
from sqlalchemy import create_engine, text

@pytest.fixture
def alembic_config():
    """Create Alembic configuration for testing"""
    config = Config("alembic.ini")
    config.set_main_option("sqlalchemy.url", TEST_DATABASE_URL)
    return config

def test_migrations_up_down(alembic_config, test_engine):
    """Test database migrations up and down"""
    # Upgrade to head
    command.upgrade(alembic_config, "head")
    
    # Verify tables exist
    with test_engine.connect() as conn:
        result = conn.execute(text(
            "SELECT table_name FROM information_schema.tables "
            "WHERE table_schema='public'"
        ))
        tables = [row[0] for row in result]
        assert "users" in tables
        assert "organizations" in tables
    
    # Downgrade to base
    command.downgrade(alembic_config, "base")
    
    # Verify tables removed
    with test_engine.connect() as conn:
        result = conn.execute(text(
            "SELECT table_name FROM information_schema.tables "
            "WHERE table_schema='public'"
        ))
        tables = [row[0] for row in result]
        assert len(tables) == 0

def test_migration_data_integrity(alembic_config, test_engine):
    """Test data integrity during migrations"""
    # Upgrade to specific revision
    command.upgrade(alembic_config, "abc123")  # Replace with actual revision
    
    # Insert test data
    with test_engine.connect() as conn:
        conn.execute(text(
            "INSERT INTO users (email, name) VALUES (:email, :name)"
        ), {"email": "test@example.com", "name": "Test User"})
        conn.commit()
    
    # Upgrade to next revision
    command.upgrade(alembic_config, "def456")  # Replace with actual revision
    
    # Verify data still exists
    with test_engine.connect() as conn:
        result = conn.execute(text("SELECT * FROM users WHERE email = :email"),
                             {"email": "test@example.com"})
        assert result.rowcount == 1
```

### **End-to-End Service Testing**
```python
import pytest
import asyncio
from testcontainers.postgres import PostgresContainer
from testcontainers.redis import RedisContainer
from testcontainers.kafka import KafkaContainer

@pytest.fixture(scope="session")
async def test_infrastructure():
    """Start complete test infrastructure"""
    # Start PostgreSQL
    postgres = PostgresContainer("postgres:17")
    postgres.start()
    
    # Start Redis
    redis = RedisContainer("redis:7-alpine")
    redis.start()
    
    # Start Kafka (if needed)
    kafka = KafkaContainer("confluentinc/cp-kafka:latest")
    kafka.start()
    
    # Set environment variables
    os.environ["DATABASE_URL"] = postgres.get_connection_url()
    os.environ["REDIS_URL"] = f"redis://{redis.get_container_host_ip()}:{redis.get_exposed_port(6379)}"
    os.environ["KAFKA_BOOTSTRAP_SERVERS"] = kafka.get_bootstrap_server()
    
    yield {
        "postgres": postgres,
        "redis": redis,
        "kafka": kafka
    }
    
    # Cleanup
    kafka.stop()
    redis.stop()
    postgres.stop()

@pytest.mark.e2e
async def test_full_user_journey(test_infrastructure, client):
    """Test complete user journey across services"""
    # 1. Register user
    response = client.post("/api/v1/auth/register", json={
        "email": "newuser@example.com",
        "password": "SecurePass123!",
        "name": "New User"
    })
    assert response.status_code == 201
    
    # 2. Login
    response = client.post("/api/v1/auth/login", json={
        "email": "newuser@example.com",
        "password": "SecurePass123!"
    })
    assert response.status_code == 200
    token = response.json()["access_token"]
    
    # 3. Upload document
    headers = {"Authorization": f"Bearer {token}"}
    files = {"file": ("test.pdf", b"PDF content", "application/pdf")}
    response = client.post("/api/v1/documents", 
                          files=files,
                          headers=headers)
    assert response.status_code == 200
    doc_id = response.json()["id"]
    
    # 4. Create workflow
    response = client.post("/api/v1/workflows", json={
        "name": "Document Review",
        "document_id": doc_id
    }, headers=headers)
    assert response.status_code == 201
    
    # 5. Send notification
    response = client.post("/api/v1/notifications", json={
        "type": "email",
        "to": "newuser@example.com",
        "subject": "Document uploaded",
        "message": "Your document has been uploaded successfully"
    }, headers=headers)
    assert response.status_code == 200
```

## ðŸ”„ **Continuous Improvement**

### **Test Maintenance**
- Regularly review and update test cases
- Remove obsolete tests when features change
- Refactor tests when code structure changes
- Monitor test execution time and optimize slow tests
- Keep test dependencies up to date
- Track flaky tests and fix root causes
- Maintain test documentation

### **Quality Metrics Dashboard**
```python
# Create test metrics report
def generate_test_metrics():
    """Generate comprehensive test metrics report"""
    import coverage
    import pytest
    
    # Run tests with coverage
    cov = coverage.Coverage()
    cov.start()
    
    pytest.main([
        "--cov=.",
        "--cov-report=json",
        "--json-report",
        "--json-report-file=test-report.json"
    ])
    
    cov.stop()
    cov.save()
    
    # Parse results
    import json
    with open("test-report.json") as f:
        report = json.load(f)
    
    metrics = {
        "total_tests": report["summary"]["total"],
        "passed": report["summary"]["passed"],
        "failed": report["summary"]["failed"],
        "skipped": report["summary"]["skipped"],
        "coverage": cov.report(),
        "execution_time": report["duration"],
        "test_categories": {
            "unit": len([t for t in report["tests"] if "unit" in t["nodeid"]]),
            "integration": len([t for t in report["tests"] if "integration" in t["nodeid"]]),
            "e2e": len([t for t in report["tests"] if "e2e" in t["nodeid"]])
        }
    }
    
    return metrics
```

### **Automated Test Quality Checks**
```bash
# Pre-commit hook for test quality
#!/bin/bash
# .git/hooks/pre-commit

# Run tests before commit
pytest tests/unit --fail-under=90

# Check for console.log or print statements in tests
grep -r "console.log\|print(" tests/ && echo "Remove debug statements from tests" && exit 1

# Check for focused tests
grep -r "\.only\|@pytest.mark.only" tests/ && echo "Remove focused tests" && exit 1

# Check test naming conventions
find tests -name "*.py" -exec grep -L "^def test_" {} \; && echo "All test functions must start with test_" && exit 1

exit 0
```

---

**ðŸ§ª This standardized testing approach ensures all microservices maintain high quality, reliability, and consistency across the entire system!**

---

**Document Maintainer**: Services Coordinator Agent  
**Last Updated**: 2025-09-09  
**Version**: 2.0 - Enhanced with Docker testing, migration testing, and service-specific examples  
**Next Review**: After first service implements complete test suite

---

## ðŸ“Š **Quick Reference - Test Coverage Goals**

| Test Type | Coverage Target | Priority |
|-----------|----------------|----------|
| **Unit Tests** | >90% | Critical |
| **Integration Tests** | >70% | High |
| **API Endpoints** | 100% | Critical |
| **Authentication** | 100% | Critical |
| **Error Handling** | 100% | High |
| **Edge Cases** | >80% | Medium |
| **Performance** | Key paths | Medium |
| **E2E Tests** | Critical flows | High |